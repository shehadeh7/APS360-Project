{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pydub\n",
        "! pip install noisereduce\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "YzrCinDpFibG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78519d1a-01de-4aca-9538-ae2f3e6d5fbe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from noisereduce) (4.63.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from noisereduce) (0.8.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from noisereduce) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.21.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->noisereduce) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->noisereduce) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa->noisereduce) (3.0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->noisereduce) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa->noisereduce) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->noisereduce) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->noisereduce) (3.10.0.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from Kaggle (direct link: https://www.kaggle.com/dmitrybabko/speech-emotion-recognition-en)\n",
        "!kaggle datasets download dmitrybabko/speech-emotion-recognition-en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVbPW-ZrFnDM",
        "outputId": "1b5abbe9-758e-479b-fe70-e3754275fa34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speech-emotion-recognition-en.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data"
      ],
      "metadata": {
        "id": "chYD-BvHFsBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip speech-emotion-recognition-en.zip -d ./data"
      ],
      "metadata": {
        "id": "FqFe2nfCFwBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import shuffle\n",
        "import librosa"
      ],
      "metadata": {
        "id": "oXDirr09eM4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = {\n",
        "  'happy': 0, \n",
        "  'sad': 1, \n",
        "  'angry': 2\n",
        "}\n",
        "\n",
        "ravdess_emotions = {\n",
        "    '03': emotions['happy'],\n",
        "    '04': emotions['sad'],\n",
        "    '05': emotions['angry']\n",
        "}\n",
        "\n",
        "crema_emotions = {\n",
        "  'SAD': emotions['sad'], \n",
        "  'ANG': emotions['angry'],\n",
        "  'HAP': emotions['happy']\n",
        "}\n",
        "\n",
        "savee_emotions = {\n",
        "    'a': emotions['angry'],\n",
        "    'h': emotions['happy']\n",
        "}\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "data_path = \"/content/data\"\n",
        "for root, dirs, files in os.walk(data_path):\n",
        "  for file in files:\n",
        "    file_path = os.path.join(root, file)\n",
        "\n",
        "    emotion_label = None\n",
        "\n",
        "    dataset = file_path.split('/')[3]\n",
        "    if dataset == 'Ravdess':\n",
        "      emotion_label = ravdess_emotions.get(file.split('-')[2], None)\n",
        "    elif dataset == 'Crema':\n",
        "      emotion_label = crema_emotions.get(file.split('_')[2], None)\n",
        "    elif dataset == 'Tess':\n",
        "      emotion_label = emotions.get(file.split('_')[2].split('.')[0], None)\n",
        "    elif dataset == 'Savee':\n",
        "      emotion_code = file.split('_')[1][:2]\n",
        "      if (emotion_code == 'sa'):\n",
        "        emotion_label = emotions['sad']\n",
        "      else:\n",
        "        emotion_label = savee_emotions.get(emotion_code[0], None)\n",
        "\n",
        "    if (emotion_label != None):\n",
        "      processed_data.append([file_path, dataset, emotion_label])"
      ],
      "metadata": {
        "id": "Ri1CwRaWFZ1b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import noisereduce as nr\n",
        "from pydub import AudioSegment, effects\n",
        "\n",
        "\n",
        "frame_length = 2048\n",
        "hop_length = 512\n",
        "total_length = 157409 # verify this value?\n",
        "\n",
        "def extract_feature(file_name): \n",
        "\n",
        "    y, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "\n",
        "    # Don't process corrupted audio signals\n",
        "    if not np.any(y):\n",
        "        return None\n",
        "\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate,n_mfcc=40).T, axis=0)\n",
        "\n",
        "    return mfccs\n",
        "\n",
        "def extract_all_features(file_name):\n",
        "\n",
        "    y, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "\n",
        "    # Don't process corrupted audio signals\n",
        "    if not np.any(y):\n",
        "        return None\n",
        "\n",
        "    rawsound = AudioSegment.from_file(file_name) \n",
        "    # Normalize the audio to +5.0 dBFS.\n",
        "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the normalized audio to np.array of samples.\n",
        "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Trim silence from the beginning and the end.\n",
        "    xt, index = librosa.effects.trim(normal_x, top_db=30)\n",
        "    # Pad for duration equalization.\n",
        "    padded_x = librosa.util.fix_length(xt, size=total_length)\n",
        "    # Noise reduction.\n",
        "    final_x = nr.reduce_noise(y=padded_x, sr=sample_rate)        \n",
        "\n",
        "    stft = np.abs(librosa.stft(final_x))\n",
        "    result=np.array([])\n",
        "    \n",
        "    mfccs=np.mean(librosa.feature.mfcc(y=final_x, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result=np.hstack((result, mfccs))\n",
        "\n",
        "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    result=np.hstack((result, chroma))\n",
        "\n",
        "    mel=np.mean(librosa.feature.melspectrogram(final_x, sr=sample_rate).T,axis=0)\n",
        "    result=np.hstack((result, mel))\n",
        "\n",
        "    return result        "
      ],
      "metadata": {
        "id": "0SXxFv1BF5nK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain features from each wav file\n",
        "labels = []\n",
        "features = []\n",
        "\n",
        "i = 0 # partially save results?\n",
        "for data in processed_data:\n",
        "    i += 1\n",
        "    result = extract_feature(data[0])\n",
        "    if result is not None:\n",
        "        labels.append(data[2])\n",
        "        features.append(result)\n",
        "    if i%500 == 0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "7tYOHrEuF9Uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35db439c-2a6d-40fc-9767-82536f6ef13a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "1000\n",
            "1500\n",
            "2000\n",
            "2500\n",
            "3000\n",
            "3500\n",
            "4000\n",
            "4500\n",
            "5000\n",
            "5500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create np arrays for data and labels\n",
        "X = np.array(features)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "W18XOwWDgNc6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle X and Y same way\n",
        "# random_state to seed the shuffle\n",
        "# X, Y = shuffle(X, Y, random_state=0)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "J8CjRiD9GGFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be04577-5df9-49a2-a578-6d9940a4531a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5768, 40)\n",
            "(5768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rT0A8B6NdK77"
      },
      "outputs": [],
      "source": [
        "#numpy save x and y\n",
        "#zip together before saving?\n",
        "x_path = './x_data'\n",
        "y_path = './y_data'\n",
        "np.save(x_path, X)\n",
        "np.save(y_path, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "B2h4rCf6ebC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2346864-999f-4dde-960c-46017708f645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: x_data.npy (deflated 6%)\n",
            "  adding: y_data.npy (deflated 95%)\n"
          ]
        }
      ],
      "source": [
        "! zip allData_threeEmotions.zip x_data.npy y_data.npy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import shuffle\n",
        "import librosa\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pmrf9ty6bpHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_0, X_test, y_train_0, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_0, y_train_0, test_size=0.18, random_state=42) # 0.18 x 0.85 = 0.15"
      ],
      "metadata": {
        "id": "WOlE_L7wbv-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "#                 Model Section                     #\n",
        "#####################################################\n",
        "\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_valcnn = np.expand_dims(X_val, axis=2)\n",
        "\n",
        "print(x_traincnn.shape, x_valcnn.shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(128, 5, padding='same',\n",
        "                    input_shape=(182, 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(tf.keras.layers.MaxPool1D())\n",
        "model.add(Conv1D(176, 5, padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(tf.keras.layers.MaxPool1D())\n",
        "model.add(Conv1D(240, 5, padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer='rmsprop',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_traincnn, y_train,\n",
        "                        batch_size=16, epochs=50,\n",
        "                        validation_data=(x_valcnn, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byGZQ4FDbx2-",
        "outputId": "4bae27d6-c5d9-4c67-9ae7-0a62b32e7944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2701, 180, 1) (593, 180, 1)\n",
            "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x7f5a0d984910>>\n",
            "Epoch 1/50\n",
            "169/169 [==============================] - 14s 77ms/step - loss: 1.3594 - accuracy: 0.5254 - val_loss: 1.0682 - val_accuracy: 0.6779\n",
            "Epoch 2/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.9811 - accuracy: 0.6731 - val_loss: 0.9012 - val_accuracy: 0.6931\n",
            "Epoch 3/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.8516 - accuracy: 0.7197 - val_loss: 0.9058 - val_accuracy: 0.6830\n",
            "Epoch 4/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.7840 - accuracy: 0.7360 - val_loss: 0.9167 - val_accuracy: 0.6880\n",
            "Epoch 5/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.7275 - accuracy: 0.7549 - val_loss: 0.8254 - val_accuracy: 0.7116\n",
            "Epoch 6/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.7090 - accuracy: 0.7634 - val_loss: 0.8531 - val_accuracy: 0.7268\n",
            "Epoch 7/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.6790 - accuracy: 0.7716 - val_loss: 0.9735 - val_accuracy: 0.6863\n",
            "Epoch 8/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.6306 - accuracy: 0.7897 - val_loss: 0.8375 - val_accuracy: 0.7302\n",
            "Epoch 9/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.5892 - accuracy: 0.7912 - val_loss: 0.8629 - val_accuracy: 0.7116\n",
            "Epoch 10/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.5993 - accuracy: 0.7916 - val_loss: 0.8482 - val_accuracy: 0.7336\n",
            "Epoch 11/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.5435 - accuracy: 0.8082 - val_loss: 0.8573 - val_accuracy: 0.7184\n",
            "Epoch 12/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.5275 - accuracy: 0.8212 - val_loss: 0.9339 - val_accuracy: 0.7083\n",
            "Epoch 13/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.5136 - accuracy: 0.8208 - val_loss: 0.9712 - val_accuracy: 0.7167\n",
            "Epoch 14/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.4865 - accuracy: 0.8460 - val_loss: 0.8969 - val_accuracy: 0.7336\n",
            "Epoch 15/50\n",
            "169/169 [==============================] - 13s 78ms/step - loss: 0.4742 - accuracy: 0.8371 - val_loss: 0.9518 - val_accuracy: 0.7150\n",
            "Epoch 16/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.4567 - accuracy: 0.8486 - val_loss: 1.0730 - val_accuracy: 0.7184\n",
            "Epoch 17/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.4461 - accuracy: 0.8512 - val_loss: 1.0818 - val_accuracy: 0.7201\n",
            "Epoch 18/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.4239 - accuracy: 0.8589 - val_loss: 1.0779 - val_accuracy: 0.7116\n",
            "Epoch 19/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.4152 - accuracy: 0.8612 - val_loss: 1.1318 - val_accuracy: 0.7218\n",
            "Epoch 20/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3903 - accuracy: 0.8682 - val_loss: 1.2893 - val_accuracy: 0.6998\n",
            "Epoch 21/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.3698 - accuracy: 0.8815 - val_loss: 1.3223 - val_accuracy: 0.7066\n",
            "Epoch 22/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.3932 - accuracy: 0.8686 - val_loss: 1.0794 - val_accuracy: 0.7234\n",
            "Epoch 23/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3339 - accuracy: 0.8856 - val_loss: 1.2903 - val_accuracy: 0.7099\n",
            "Epoch 24/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3320 - accuracy: 0.8852 - val_loss: 1.1862 - val_accuracy: 0.7049\n",
            "Epoch 25/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3074 - accuracy: 0.8960 - val_loss: 1.2250 - val_accuracy: 0.7285\n",
            "Epoch 26/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3210 - accuracy: 0.8882 - val_loss: 1.3587 - val_accuracy: 0.7133\n",
            "Epoch 27/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3147 - accuracy: 0.9008 - val_loss: 1.4288 - val_accuracy: 0.7133\n",
            "Epoch 28/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.3091 - accuracy: 0.8978 - val_loss: 1.3837 - val_accuracy: 0.7150\n",
            "Epoch 29/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.3142 - accuracy: 0.9056 - val_loss: 1.2911 - val_accuracy: 0.7184\n",
            "Epoch 30/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2842 - accuracy: 0.9086 - val_loss: 1.3959 - val_accuracy: 0.7218\n",
            "Epoch 31/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.2785 - accuracy: 0.9060 - val_loss: 1.3967 - val_accuracy: 0.7150\n",
            "Epoch 32/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.2484 - accuracy: 0.9174 - val_loss: 1.3936 - val_accuracy: 0.7251\n",
            "Epoch 33/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2872 - accuracy: 0.9185 - val_loss: 1.5461 - val_accuracy: 0.7032\n",
            "Epoch 34/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2705 - accuracy: 0.9141 - val_loss: 1.5404 - val_accuracy: 0.6981\n",
            "Epoch 35/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2523 - accuracy: 0.9174 - val_loss: 1.4895 - val_accuracy: 0.7386\n",
            "Epoch 36/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2705 - accuracy: 0.9245 - val_loss: 1.5768 - val_accuracy: 0.7201\n",
            "Epoch 37/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2618 - accuracy: 0.9226 - val_loss: 1.5850 - val_accuracy: 0.7099\n",
            "Epoch 38/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2455 - accuracy: 0.9285 - val_loss: 1.6534 - val_accuracy: 0.7218\n",
            "Epoch 39/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2441 - accuracy: 0.9263 - val_loss: 1.5570 - val_accuracy: 0.7285\n",
            "Epoch 40/50\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.2032 - accuracy: 0.9371 - val_loss: 1.8398 - val_accuracy: 0.6897\n",
            "Epoch 41/50\n",
            "169/169 [==============================] - 14s 84ms/step - loss: 0.2187 - accuracy: 0.9297 - val_loss: 1.6900 - val_accuracy: 0.7167\n",
            "Epoch 42/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2273 - accuracy: 0.9345 - val_loss: 2.0790 - val_accuracy: 0.6931\n",
            "Epoch 43/50\n",
            "169/169 [==============================] - 17s 103ms/step - loss: 0.2083 - accuracy: 0.9356 - val_loss: 1.7449 - val_accuracy: 0.7403\n",
            "Epoch 44/50\n",
            "169/169 [==============================] - 14s 82ms/step - loss: 0.2217 - accuracy: 0.9359 - val_loss: 1.8680 - val_accuracy: 0.7083\n",
            "Epoch 45/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2039 - accuracy: 0.9374 - val_loss: 2.0654 - val_accuracy: 0.6931\n",
            "Epoch 46/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.1986 - accuracy: 0.9367 - val_loss: 1.9490 - val_accuracy: 0.7133\n",
            "Epoch 47/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2499 - accuracy: 0.9363 - val_loss: 1.8808 - val_accuracy: 0.7133\n",
            "Epoch 48/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2175 - accuracy: 0.9456 - val_loss: 1.7397 - val_accuracy: 0.7218\n",
            "Epoch 49/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.1994 - accuracy: 0.9456 - val_loss: 1.7193 - val_accuracy: 0.7184\n",
            "Epoch 50/50\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.2062 - accuracy: 0.9408 - val_loss: 1.8844 - val_accuracy: 0.7218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_emotion = {\n",
        "    0:\"happy\",\n",
        "    1:\"sad\",\n",
        "    2:\"angry\",\n",
        "    3:\"disgust\",\n",
        "    4:\"fear\",\n",
        "    5:\"neutral\"\n",
        "}"
      ],
      "metadata": {
        "id": "6DYsFM9Jf8eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "from io import BytesIO\n",
        "!pip -q install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=4):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  audio = AudioSegment.from_file(BytesIO(b))\n",
        "  return audio"
      ],
      "metadata": {
        "id": "Ar31vazbgCo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = record()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ctHTvWJ9gFXJ",
        "outputId": "03744648-592a-49ef-83d3-c60973cebf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-be8bbc1b3e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-136-b835f0644ba4>\u001b[0m in \u001b[0;36mrecord\u001b[0;34m(sec)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJavascript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRECORD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'record(%d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "ipd.Audio(np.array(x.get_array_of_samples(), dtype = 'float32'), rate=x.frame_rate) # load a NumPy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "rJt32XPjgHJs",
        "outputId": "f802f5dd-b5e5-43c7-e652-0c0d67dca3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-1cde2cabfc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load a NumPy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_array_of_samples'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_rate = x.frame_rate\n",
        "y = np.array(x.get_array_of_samples(), dtype = 'float32')"
      ],
      "metadata": {
        "id": "hQwsnekAiOsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from librosa import display as dps\n",
        "# dps.waveshow(y, sr=sr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "Id2TG1mbiQjp",
        "outputId": "741c7f6a-0de3-4b11-c93c-2d66a0dbec2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<librosa.display.AdaptiveWaveplot at 0x7f5a0da660d0>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_fresh = np.array(result)\n",
        "X_fresh = X_fresh.reshape((1, X_fresh.shape[0]))\n",
        "X_fresh = np.expand_dims(X_fresh, axis=2)"
      ],
      "metadata": {
        "id": "auTWE3eJgaOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.predict(X_fresh, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YTINjlJgeci",
        "outputId": "85832cde-9438-4fe7-b187-ae3f763c1507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# emotion is argmax of out\n",
        "print(out)\n",
        "idx = np.argmax(out, axis=1)\n",
        "print(index_to_emotion[idx[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoklRbmggf6H",
        "outputId": "370890b3-9fef-41ab-8394-c7ca442d5831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 1.]]\n",
            "neutral\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "threeEmotions_dataProcessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+fkBnltiKOTbxw/m8HCnm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}