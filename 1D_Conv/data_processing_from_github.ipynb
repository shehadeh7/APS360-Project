{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shehadeh7/APS360-Project/blob/main/1D_Conv/data_processing_from_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pydub\n",
        "! pip install noisereduce\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "YzrCinDpFibG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from Kaggle (direct link: https://www.kaggle.com/dmitrybabko/speech-emotion-recognition-en)\n",
        "!kaggle datasets download dmitrybabko/speech-emotion-recognition-en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVbPW-ZrFnDM",
        "outputId": "9df9e13f-4056-49be-fa4f-7346d73e8afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading speech-emotion-recognition-en.zip to /content\n",
            "100% 987M/987M [00:11<00:00, 75.7MB/s]\n",
            "100% 987M/987M [00:11<00:00, 92.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data"
      ],
      "metadata": {
        "id": "chYD-BvHFsBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip speech-emotion-recognition-en.zip -d ./data"
      ],
      "metadata": {
        "id": "FqFe2nfCFwBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "oXDirr09eM4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = {\n",
        "  'happy': 0, \n",
        "  'sad': 1, \n",
        "  'angry': 2, \n",
        "  'disgust': 3, \n",
        "  'fear': 4, \n",
        "  'neutral': 5\n",
        "}\n",
        "\n",
        "ravdess_emotions = {\n",
        "    '01': emotions['neutral'],\n",
        "    '03': emotions['happy'],\n",
        "    '04': emotions['sad'],\n",
        "    '05': emotions['angry'],\n",
        "    '06': emotions['fear'],\n",
        "    '07': emotions['disgust'],\n",
        "}\n",
        "\n",
        "crema_emotions = {\n",
        "  'SAD': emotions['sad'], \n",
        "  'ANG': emotions['angry'], \n",
        "  'DIS': emotions['disgust'],\n",
        "  'FEA': emotions['fear'], \n",
        "  'HAP': emotions['happy'], \n",
        "  'NEU': emotions['neutral']\n",
        "}\n",
        "\n",
        "savee_emotions = {\n",
        "    'a': emotions['angry'],\n",
        "    'd': emotions['disgust'],\n",
        "    'f': emotions['fear'],\n",
        "    'h': emotions['happy'],\n",
        "    'n': emotions['neutral']\n",
        "}\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "data_path = \"/content/data\"\n",
        "for root, dirs, files in os.walk(data_path):\n",
        "  for file in files:\n",
        "    file_path = os.path.join(root, file)\n",
        "\n",
        "    emotion_label = None\n",
        "\n",
        "    dataset = file_path.split('/')[3]\n",
        "    if dataset == 'Ravdess':\n",
        "      emotion_label = ravdess_emotions.get(file.split('-')[2], None)\n",
        "    # elif dataset == 'Crema':\n",
        "    #   emotion_label = crema_emotions.get(file.split('_')[2], None)\n",
        "    elif dataset == 'Tess':\n",
        "      emotion_label = emotions.get(file.split('_')[2].split('.')[0], None)\n",
        "    elif dataset == 'Savee':\n",
        "      emotion_code = file.split('_')[1][:2]\n",
        "      if (emotion_code == 'sa'):\n",
        "        emotion_label = emotions['sad']\n",
        "      else:\n",
        "        emotion_label = savee_emotions.get(emotion_code[0], None)\n",
        "\n",
        "    if (emotion_label != None):\n",
        "      processed_data.append([file_path, dataset, emotion_label])"
      ],
      "metadata": {
        "id": "Ri1CwRaWFZ1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "def extract_feature(file_name): \n",
        "\n",
        "    y, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "\n",
        "    # Don't process corrupted audio signals\n",
        "    if not np.any(y):\n",
        "        return None\n",
        "\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate,n_mfcc=40).T, axis=0)\n",
        "\n",
        "    return mfccs"
      ],
      "metadata": {
        "id": "0SXxFv1BF5nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain features from each wav file\n",
        "labels = []\n",
        "features = []\n",
        "\n",
        "i = 0 # partially save results?\n",
        "for data in processed_data:\n",
        "    i += 1\n",
        "    result = extract_feature(data[0])\n",
        "    if result is not None:\n",
        "        labels.append(data[2])\n",
        "        features.append(result)\n",
        "    if i%100 == 0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "7tYOHrEuF9Uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b51fdae-a08a-4c46-d04e-ae0b18b556b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create np arrays for data and labels\n",
        "X = np.array(features)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "W18XOwWDgNc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle X and Y same way\n",
        "# random_state to seed the shuffle\n",
        "# X, Y = shuffle(X, Y, random_state=0)\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "J8CjRiD9GGFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44bca28-b758-43d7-feba-41adcfa3e408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3876, 40)\n",
            "(3876,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT0A8B6NdK77"
      },
      "outputs": [],
      "source": [
        "#numpy save x and y\n",
        "#zip together before saving?\n",
        "x_path = './x_data'\n",
        "y_path = './y_data'\n",
        "np.save(x_path, X)\n",
        "np.save(y_path, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2h4rCf6ebC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5302e4a-043b-4f00-90c6-7bfe8400bd75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: x_data.npy (deflated 7%)\n",
            "  adding: y_data.npy (deflated 96%)\n"
          ]
        }
      ],
      "source": [
        "! zip github_fork_data.zip x_data.npy y_data.npy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "processing_model_from_github.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA7b3/oYqA8xXmadJ/mRTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}