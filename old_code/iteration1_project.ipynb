{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APS360_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPU0LWlZILlLlhYNUnxZP7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shehadeh7/APS360-Project/blob/main/APS360_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pydub\n",
        "! pip install noisereduce"
      ],
      "metadata": {
        "id": "XBlfa-1Ye181"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "RD_jaOVQsfjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset from Kaggle (direct link: https://www.kaggle.com/dmitrybabko/speech-emotion-recognition-en)\n",
        "!kaggle datasets download dmitrybabko/speech-emotion-recognition-en"
      ],
      "metadata": {
        "id": "hzgVpHk5d_Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./data"
      ],
      "metadata": {
        "id": "9lIkF3LyeBc4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip speech-emotion-recognition-en.zip -d ./data"
      ],
      "metadata": {
        "id": "dtOzdUegeDvj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "emotions = {\n",
        "  'happy': 0, \n",
        "  'sad': 1, \n",
        "  'angry': 2, \n",
        "  'disgust': 3, \n",
        "  'fear': 4, \n",
        "  'neutral': 5\n",
        "}\n",
        "\n",
        "ravdess_emotions = {\n",
        "    '01': emotions['neutral'],\n",
        "    '03': emotions['happy'],\n",
        "    '04': emotions['sad'],\n",
        "    '05': emotions['angry'],\n",
        "    '06': emotions['fear'],\n",
        "    '07': emotions['disgust'],\n",
        "}\n",
        "\n",
        "crema_emotions = {\n",
        "  'SAD': emotions['sad'], \n",
        "  'ANG': emotions['angry'], \n",
        "  'DIS': emotions['disgust'],\n",
        "  'FEA': emotions['fear'], \n",
        "  'HAP': emotions['happy'], \n",
        "  'NEU': emotions['neutral']\n",
        "}\n",
        "\n",
        "savee_emotions = {\n",
        "    'a': emotions['angry'],\n",
        "    'd': emotions['disgust'],\n",
        "    'f': emotions['fear'],\n",
        "    'h': emotions['happy'],\n",
        "    'n': emotions['neutral']\n",
        "}\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "data_path = \"/content/data\"\n",
        "for root, dirs, files in os.walk(data_path):\n",
        "  for file in files:\n",
        "    file_path = os.path.join(root, file)\n",
        "\n",
        "    dataset = file_path.split('/')[3]\n",
        "    if dataset == 'Ravdess':\n",
        "      emotion_label = ravdess_emotions.get(file.split('-')[2], None)\n",
        "    elif dataset == 'Crema':\n",
        "      emotion_label = crema_emotions.get(file.split('_')[2], None)\n",
        "    elif dataset == 'Tess':\n",
        "      emotion_label = emotions.get(file.split('_')[2].split('.')[0], None)\n",
        "    else:\n",
        "      emotion_code = file.split('_')[1][:2]\n",
        "      if (emotion_code == 'sa'):\n",
        "        emotion_label = emotions['sad']\n",
        "      else:\n",
        "        emotion_label = savee_emotions.get(emotion_code[0], None)\n",
        "\n",
        "    if (emotion_label != None):\n",
        "      processed_data.append([file_path, dataset, emotion_label])"
      ],
      "metadata": {
        "id": "1ryrsXk8S6r4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "from pydub import AudioSegment, effects\n",
        "import noisereduce as nr\n",
        "\n",
        "frame_length = 2048\n",
        "hop_length = 512\n",
        "total_length = 180000 # verify this value?\n",
        "\n",
        "def extract_feature(file_name): \n",
        "\n",
        "    _, sample_rate = librosa.load(file_name, sr=None)\n",
        "\n",
        "    rawsound = AudioSegment.from_file(file_name) \n",
        "    # Normalize the audio to +5.0 dBFS.\n",
        "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the normalized audio to np.array of samples.\n",
        "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Trim silence from the beginning and the end.\n",
        "    xt, index = librosa.effects.trim(normal_x, top_db=30)\n",
        "    # Pad for duration equalization.\n",
        "    padded_x = librosa.util.fix_length(xt, size=total_length)\n",
        "    # Noise reduction.\n",
        "    final_x = nr.reduce_noise(y=padded_x, sr=sample_rate)\n",
        "    \n",
        "    # Features extraction   \n",
        "    stft = np.abs(librosa.stft(final_x))\n",
        "    mfccs = librosa.feature.mfcc(y=final_x, sr=sample_rate, n_mfcc=15)\n",
        "    chroma = librosa.feature.chroma_stft(S=stft, sr=sample_rate)\n",
        "    mel = librosa.feature.melspectrogram(final_x, sr=sample_rate)\n",
        "    contrast = librosa.feature.spectral_contrast(S=stft, sr=sample_rate)\n",
        "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(final_x), sr=sample_rate)\n",
        "    return mfccs,chroma,mel,contrast,tonnetz\n"
      ],
      "metadata": {
        "id": "RcACKgLXUtg1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(processed_data)"
      ],
      "metadata": {
        "id": "uXq55BxZftlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain features from each wav file\n",
        "labels = []\n",
        "features = []\n",
        "i = 0\n",
        "\n",
        "mfccs = []\n",
        "chroma = []\n",
        "mel = []\n",
        "contrast = []\n",
        "tonnetz = []\n",
        "mylists = [mfccs, chroma, mel, contrast, tonnetz]\n",
        "for data in processed_data:\n",
        "    labels.append(data[2])\n",
        "    result = extract_feature(data[0])\n",
        "    for x, lst in zip(result, mylists):\n",
        "        lst.append(x)\n",
        "    i+=1\n",
        "    if (i>=1000):\n",
        "        break\n"
      ],
      "metadata": {
        "id": "V6BLxL7eYF32"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change feature lists to np array of size timestamp x features\n",
        "a_mfccs = np.asarray(mfccs).astype('float32')\n",
        "a_mfccs = np.swapaxes(a_mfccs, 1, 2)\n",
        "a_chroma = np.asarray(chroma).astype('float32')\n",
        "a_chroma = np.swapaxes(a_chroma, 1, 2)\n",
        "a_mel = np.asarray(mel).astype('float32')\n",
        "a_mel = np.swapaxes(a_mel, 1, 2)\n",
        "a_contrast = np.asarray(contrast).astype('float32')\n",
        "a_contrast = np.swapaxes(a_contrast, 1, 2)\n",
        "a_tonnetz = np.asarray(tonnetz).astype('float32')\n",
        "a_tonnetz = np.swapaxes(a_tonnetz, 1, 2)\n",
        "\n",
        "print('MFCCS shape:',a_mfccs.shape)\n",
        "print('CHROMA shape:',a_chroma.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIbvVXUGm832",
        "outputId": "6dc9ed26-3624-437a-fa65-e2412ad8b3a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCCS shape: (1000, 352, 15)\n",
            "CHROMA shape: (1000, 352, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create np arrays for data and labels\n",
        "X = np.concatenate((a_mfccs, a_chroma, a_mel, a_contrast, a_tonnetz), axis=2)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "rvWo2y9aonen"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# dataSize = 1000\n",
        "# testSplit = 0.1 # 10% for testsplit\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "# Flatten X to a 2d array for random forest\n",
        "nsamples, nx, ny = X.shape\n",
        "X_2d = X.reshape((nsamples,nx*ny))\n",
        "clf.fit(X_2d[:800,:], Y[:800])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT0A8B6NdK77",
        "outputId": "3eec00f1-0ed0-48a5-f1f2-aa200e4a0702"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(X_2d[800:,:])\n",
        "\n",
        "pscore = sklearn.metrics.accuracy_score(y_pred, Y[800:])\n",
        "print(pscore)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2h4rCf6ebC4",
        "outputId": "525f9f7b-06ff-4ffc-9258-a3c422f4ee6f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.515\n"
          ]
        }
      ]
    }
  ]
}
